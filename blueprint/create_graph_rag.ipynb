{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d825580-387d-4fc0-b441-e44cfe6bb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import hashlib\n",
    "from datasets import load_dataset\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea63470-a88f-4567-9090-fbcc61d123c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4577c9c5-6b93-420d-93dc-a496fd0003cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data, test_data = load_dataset(\"suolyer/pile_wikipedia\", split=['validation', 'test'])\n",
    "\n",
    "data = []\n",
    "random_rows = random.sample(range(len(test_data)), 10)\n",
    "build_data = [test_data[val]['text'] for val in random_rows]\n",
    "\n",
    "m = hashlib.md5()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def bert_len(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def create_chunk_dataset(content):\n",
    "      m.update(content.encode('utf-8'))\n",
    "      uid = m.hexdigest()[:12]\n",
    "      text_splitter = RecursiveCharacterTextSplitter(\n",
    "          chunk_size = 400,\n",
    "          chunk_overlap  = 40,\n",
    "          length_function = bert_len,\n",
    "          separators=['\\n\\n', '\\n', ' ', ''],\n",
    "      )\n",
    "      chunks = text_splitter.split_text(content)\n",
    "      for i, chunk in enumerate(chunks):\n",
    "          data.append({\n",
    "              'id': f'{uid}-{i}',\n",
    "              'text': chunk\n",
    "          })\n",
    "\n",
    "for dt in build_data:\n",
    "    create_chunk_dataset(dt)\n",
    "\n",
    "filename = './kg/data/knowledge graphs/rebel_llamaindex/wiki_chunks.json'\n",
    "# save\n",
    "with open(filename, 'w') as outfile:\n",
    "    for x in data:\n",
    "        outfile.write(json.dumps(x) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00dd3b-37f9-4be8-82c7-71d5d78844af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REBEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8069e40-06da-47ca-b815-182a27e773c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/torch/onnx/_internal/_beartype.py:30: UserWarning: unhashable type: 'list'\n",
      "  warnings.warn(f\"{e}\")\n",
      "2023-10-31 17:49:07.951667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bbc1efcbc24f5e8b076223fa313e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    #print(text)\n",
    "    #print(text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\"))\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        #print(token)\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"max_length\": 256,\n",
    "    \"length_penalty\": 0,\n",
    "    \"num_beams\": 3,\n",
    "    \"num_return_sequences\": 1,\n",
    "}\n",
    "\n",
    "triples = []\n",
    "\n",
    "def generate_triples(texts):\n",
    "\n",
    "  model_inputs = tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "  generated_tokens = model.generate(\n",
    "      model_inputs[\"input_ids\"].to(model.device),\n",
    "      attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "      **gen_kwargs\n",
    "  )\n",
    "  decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "  for idx, sentence in enumerate(decoded_preds):\n",
    "      #print(sentence)\n",
    "      et = extract_triplets(sentence)\n",
    "      for t in et:\n",
    "        triples.append((t['head'], t['type'], t['tail']))\n",
    "\n",
    "for i in tqdm(range(0, len(data), 2)):\n",
    "  try:\n",
    "    texts = [data[i]['text'], data[i+1]['text']]\n",
    "  except:\n",
    "    texts = [data[i]['text']]\n",
    "  #print(texts)\n",
    "  generate_triples(texts)\n",
    "\n",
    "distinct_triples = list(set(triples))\n",
    "\n",
    "# save\n",
    "with open('./kg/data/knowledge graphs/rebel_llamaindex/rebel_triples.json', 'w') as file:\n",
    "    json.dump(distinct_triples, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7500fc38-45aa-43d9-9c86-7223883fe954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neal Dunn', 'member of political party', 'R'),\n",
       " ('Otaru Music Box Museum',\n",
       "  'located in the administrative territorial entity',\n",
       "  'Otaru'),\n",
       " ('Northwood Mall',\n",
       "  'located in the administrative territorial entity',\n",
       "  'Tallahassee'),\n",
       " ('Theobald of Marly', 'position held', 'abbot'),\n",
       " ('LeRoy Collins', 'position held', 'Governor of Florida')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_triples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479084b9-6937-46dc-89bf-8faad2910779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LlamaIndex KnowledgeGraphIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a056cd98-5aa4-4ca5-8cc9-c09ad93df2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.indices.service_context:chunk_size_limit is deprecated, please specify chunk_size instead\n",
      "/home/jin/grap_rag\n",
      "<class 'list'>\n",
      "(Neal Dunn, member of political party, R)\n",
      "(Otaru Music Box Museum, located in, Otaru)\n",
      "(Northwood Mall, located in, Tallahassee)\n",
      "(Theobald of Marly, position held, abbot)\n",
      "(LeRoy Collins, position held, Governor of Florida)\n",
      "(State University System of Florida, is, subsidiary of, Florida A&M University)\n",
      "(Economic Offences Wing, is part of, Mumbai police)\n",
      "(Renhuai City, contains administrative territorial entity, Sanhe, Renhuai)\n",
      "(Mike Gordon, date of death, June 25, 2005)\n",
      "(Tonyo, place of death, Sapporo)\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "(Kita Kita, is, Philippine romantic comedy film)\n",
      "(Kita Kita, written and directed by, Sigrid Andrea P. Bernardo)\n",
      "(Kita Kita, starring, Alessandra de Rossi and Empoy Marquez)\n",
      "(Kita Kita, set in, Sapporo)\n",
      "(Kita Kita, follows, Lea)\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "(Lea, walks out, collapses)\n",
      "(Tonyo, introduces himself to, Lea)\n",
      "(Lea, falls in love with, Tonyo)\n",
      "(Tonyo, leaves, Lea)\n",
      "(Tonyo, is hit by, vehicle)\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "(Empoy Marquez, portrayed, Tonyo)\n",
      "(Tonyo, was written for, Empoy Marquez)\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "(Kita Kita, focuses on, concept of \"falling in love even if you don't see the person\")\n",
      "(Kita Kita, focuses on, Overseas Filipino Workers)\n",
      "(Kita Kita, made by, Spring Films)\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "(Pascual, did, voice role)\n",
      "(Boy Y\\u00f1iguez, was, cinematographer)\n",
      "(Kita Kita, was, filmed in Hokkaido)\n",
      "(Kita Kita, was, filmed in Sapporo)\n",
      "(Kita Kita, was, filmed in Otaru)\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "(Kita Kita, premiered at, Osaka Asian Film Festival)\n",
      "(Kita Kita, vied for, Grand Prix)\n",
      "(Kita Kita, vied for, Most Promising Talent awards)\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "(Kita Kita, screened at, film festival)\n",
      "(Kita Kita, submitted to, Metro Manila Film Festival)\n",
      "(Kita Kita, premiered in, Philippines)\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per day. Limit: 200 / day. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per day. Limit: 200 / day. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per day. Limit: 200 / day. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per day. Limit: 200 / day. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per day. Limit: 200 / day. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per day. Limit: 200 / day. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m documents \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(documents))\n\u001b[0;32m---> 68\u001b[0m kg_index \u001b[38;5;241m=\u001b[39m \u001b[43mKnowledgeGraphIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_triplets_per_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrel_prop_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_prop_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrieverQueryEngine\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KnowledgeGraphRAGRetriever\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/indices/base.py:102\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[0;34m(cls, documents, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[1;32m     98\u001b[0m nodes \u001b[38;5;241m=\u001b[39m service_context\u001b[38;5;241m.\u001b[39mnode_parser\u001b[38;5;241m.\u001b[39mget_nodes_from_documents(\n\u001b[1;32m     99\u001b[0m     documents, show_progress\u001b[38;5;241m=\u001b[39mshow_progress\n\u001b[1;32m    100\u001b[0m )\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/indices/knowledge_graph/base.py:85\u001b[0m, in \u001b[0;36mKnowledgeGraphIndex.__init__\u001b[0;34m(self, nodes, index_struct, service_context, storage_context, kg_triple_extract_template, max_triplets_per_chunk, include_embeddings, show_progress, max_object_length, kg_triplet_extract_fn, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_object_length \u001b[38;5;241m=\u001b[39m max_object_length\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kg_triplet_extract_fn \u001b[38;5;241m=\u001b[39m kg_triplet_extract_fn\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# TODO: legacy conversion - remove in next release\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_struct\u001b[38;5;241m.\u001b[39mtable) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_store, SimpleGraphStore)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_store\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mgraph_dict) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     99\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/indices/base.py:71\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/indices/base.py:171\u001b[0m, in \u001b[0;36mBaseIndex.build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build the index from nodes.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docstore\u001b[38;5;241m.\u001b[39madd_documents(nodes, allow_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/indices/knowledge_graph/base.py:172\u001b[0m, in \u001b[0;36mKnowledgeGraphIndex._build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    168\u001b[0m nodes_with_progress \u001b[38;5;241m=\u001b[39m get_tqdm_iterable(\n\u001b[1;32m    169\u001b[0m     nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_progress, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes_with_progress:\n\u001b[0;32m--> 172\u001b[0m     triplets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_triplets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Extracted triplets: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtriplets\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m triplet \u001b[38;5;129;01min\u001b[39;00m triplets:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/indices/knowledge_graph/base.py:122\u001b[0m, in \u001b[0;36mKnowledgeGraphIndex._extract_triplets\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kg_triplet_extract_fn(text)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm_extract_triplets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/indices/knowledge_graph/base.py:126\u001b[0m, in \u001b[0;36mKnowledgeGraphIndex._llm_extract_triplets\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_llm_extract_triplets\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m    125\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract keywords from text.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_service_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkg_triple_extract_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_triplet_response(\n\u001b[1;32m    132\u001b[0m         response, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_object_length\n\u001b[1;32m    133\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/llm_predictor/base.py:196\u001b[0m, in \u001b[0;36mLLMPredictor.predict\u001b[0;34m(self, prompt, output_cls, **prompt_args)\u001b[0m\n\u001b[1;32m    194\u001b[0m     formatted_prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[1;32m    195\u001b[0m     formatted_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_prompt(formatted_prompt)\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    199\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/llms/base.py:312\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wrapper_logic(_self) \u001b[38;5;28;01mas\u001b[39;00m callback_manager:\n\u001b[1;32m    303\u001b[0m     event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    304\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    305\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m         },\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 312\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f_return_val, Generator):\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;66;03m# intercept the generator and add a callback to the end\u001b[39;00m\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_gen\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponseGen:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/llms/openai.py:165\u001b[0m, in \u001b[0;36mOpenAI.complete\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     complete_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplete_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/llms/openai.py:291\u001b[0m, in \u001b[0;36mOpenAI._complete\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m all_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_max_tokens(all_kwargs, prompt)\n\u001b[0;32m--> 291\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_chat_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m text \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletionResponse(\n\u001b[1;32m    300\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m    301\u001b[0m     raw\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    302\u001b[0m     additional_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_response_token_counts(response),\n\u001b[1;32m    303\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/llms/openai_utils.py:139\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(is_chat_model, max_retries, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     client \u001b[38;5;241m=\u001b[39m get_completion_endpoint(is_chat_model)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/concurrent/futures/_base.py:433\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/llama_index/llms/openai_utils.py:137\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    136\u001b[0m     client \u001b[38;5;241m=\u001b[39m get_completion_endpoint(is_chat_model)\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-3.9/lib/python3.9/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for text-davinci-002 in organization org-iPiNn7EeKnLpRRBhyzEh9l8Z on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "#os.environ[\"OPENAI_API_KEY\"] = '    '\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  \n",
    "\n",
    "from llama_index import (\n",
    "    KnowledgeGraphIndex,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "#from llama_index.llms import OpenAI\n",
    "# pip install llama-cpp-python\n",
    "from llama_index.llms import LlamaCPP\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "#llm = OpenAI(temperature=0, model=\"text-davinci-002\")\n",
    "model_url = \n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size_limit=512)\n",
    "\n",
    "# To set up NebulaGraph locally, begin by establishing a connection using its default credentials\n",
    "# Install go --> sudo snap install go --classic\n",
    "# Install nebula-console from https://github.com/vesoft-inc/nebula-console#from-source-code\n",
    "# ./nebula-console -addr 127.0.0.1 -port 9669 -u root -p nebula\n",
    "# CREATE SPACE llamaindex(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);\n",
    "# ADD HOSTS 127.0.0.1:9779;\n",
    "# :sleep 10;\n",
    "# USE llamaindex;\n",
    "# CREATE TAG entity(name string);\n",
    "# CREATE EDGE relationship(relationship string);\n",
    "# CREATE TAG INDEX entity_index ON entity(name(256));\n",
    "\n",
    "os.environ[\"NEBULA_USER\"] = \"root\"\n",
    "os.environ[\"NEBULA_PASSWORD\"] = \"nebula\"\n",
    "os.environ[\n",
    "    \"NEBULA_ADDRESS\"\n",
    "] = \"127.0.0.1:9669\"\n",
    "\n",
    "space_name = \"llamaindex\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "] \n",
    "tags = [\"entity\"]\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "## Next, the data is loaded into the system using LlamaIndexs SimpleDirectoryReader, \n",
    "## which reads documents from a specified directory. A Knowledge Graph index, kg_index, is then constructed using these documents\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "print(os.getcwd())\n",
    "reader = SimpleDirectoryReader(input_dir=os.getcwd() + \"/kg/data/knowledge graphs/rebel_llamaindex/\")\n",
    "documents = reader.load_data()\n",
    "print(type(documents)) # <-- list, check time sleep.. try except...?\n",
    "\n",
    "kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=5,\n",
    "    service_context=service_context,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    ")\n",
    "\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers import KnowledgeGraphRAGRetriever\n",
    "\n",
    "graph_rag_retriever = KnowledgeGraphRAGRetriever(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    graph_rag_retriever, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a6eaeb-ecd8-4801-9bb0-70503b99be51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;33mGraph Store Query:\n",
      "```\n",
      "MATCH (p:`entity`)-[:relationship]->(m:`entity`) WHERE m.`entity`.`name` == 'Northwood Mall'\n",
      "RETURN p.`entity`.`name`;\n",
      "```\n",
      "\u001b[0m\u001b[1;3;33mGraph Store Response:\n",
      "{'p.entity.name': []}\n",
      "\u001b[0m\u001b[1;3;32mFinal Response: \n",
      "\n",
      "The Northwood Mall is located in the city of Omaha, Nebraska, in the United States.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"where Northwood Mall located?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e277b95-febe-43ab-afe7-148d07f663a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. REBEL + LlamaIndex KnowledgeGraphIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1e268-cd2a-4066-8a60-210dd8651127",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_name = \"rebel_llamaindex\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "]  \n",
    "tags = [\"entity\"]\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "triplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')\n",
    "rebel_kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    kg_triplet_extract_fn=extract_triplets,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=5,\n",
    "    service_context=service_context,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdbada-8331-4ba7-bf74-ad4496db47e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12340e7-daf2-48a4-ac04-809b23a1cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beec8868-eb6f-4345-b35e-a1a2a2276dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eab61b2f-b2de-4003-ac7b-fd8c0f8b90db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:nebula3.logger:Execute failed: TSocket read 0 bytes\n",
      "ERROR:llama_index.graph_stores.nebulagraph:Connection issue, try to recreate session pool. Query: WITH map{`true`: '-[', `false`: '<-['} AS arrow_l,     map{`true`: ']->', `false`: ']-'} AS arrow_r,     map{`relationship`: \"relationship\"} AS edge_type_map MATCH p=(start)-[e:`relationship`*..1]-()   WHERE id(start) IN $subjs WITH start, id(start) AS vid, nodes(p) AS nodes, e AS rels,  length(p) AS rel_count, arrow_l, arrow_r, edge_type_map WITH   REDUCE(s = vid + '{', key IN [key_ in ['', 'name']     WHERE properties(start)[key_] IS NOT NULL]  | s + key + ': ' +       COALESCE(TOSTRING(properties(start)[key]), 'null') + ', ')      + '}'    AS subj,  [item in [i IN RANGE(0, rel_count - 1)|[nodes[i], nodes[i + 1],      rels[i], typeid(rels[i]) > 0, type(rels[i]) ]] | [    arrow_l[tostring(item[3])] +      item[4] + ':' +      REDUCE(s = '{', key IN SPLIT(edge_type_map[item[4]], ',') |         s + key + ': ' + COALESCE(TOSTRING(properties(item[2])[key]),        'null') + ', ') + '}'      +    arrow_r[tostring(item[3])],    REDUCE(s = id(item[1]) + '{', key IN [key_ in         ['', 'name'] WHERE properties(item[1])[key_]         IS NOT NULL]  | s + key + ': ' +         COALESCE(TOSTRING(properties(item[1])[key]), 'null') + ', ')        + '}'    ]  ] AS rels WITH   REPLACE(subj, ', }', '}') AS subj,  REDUCE(acc = collect(NULL), l in rels | acc + l) AS flattened_rels RETURN   subj,  REPLACE(REDUCE(acc = subj, l in flattened_rels | acc + ' ' + l),     ', }', '}')     AS flattened_rels  LIMIT 100, Param: {'subjs': Value(\n",
      "    lVal=NList(\n",
      "         values=[Value(\n",
      "             sVal='Neal Dunn'),\n",
      "         Value(\n",
      "             sVal='R'),\n",
      "         Value(\n",
      "             sVal='Otaru Music Box Museum'),\n",
      "         Value(\n",
      "             sVal='Otaru'),\n",
      "         Value(\n",
      "             sVal='Northwood Mall'),\n",
      "         Value(\n",
      "             sVal='Tallahassee'),\n",
      "         Value(\n",
      "             sVal='Theobald of Marly'),\n",
      "         Value(\n",
      "             sVal='abbot'),\n",
      "         Value(\n",
      "             sVal='LeRoy Collins'),\n",
      "         Value(\n",
      "             sVal='Governor of Florida'),\n",
      "         Value(\n",
      "             sVal='Economic Offences Wing'),\n",
      "         Value(\n",
      "             sVal='Mumbai police'),\n",
      "         Value(\n",
      "             sVal='Tonyo'),\n",
      "         Value(\n",
      "             sVal='Sapporo'),\n",
      "         Value(\n",
      "             sVal='Kita Kita'),\n",
      "         Value(\n",
      "             sVal='Philippine romantic comedy film'),\n",
      "         Value(\n",
      "             sVal='Sigrid Andrea P. Bernardo'),\n",
      "         Value(\n",
      "             sVal='Alessandra de Rossi and Empoy Marquez'),\n",
      "         Value(\n",
      "             sVal='Lea'),\n",
      "         Value(\n",
      "             sVal='collapses'),\n",
      "         Value(\n",
      "             sVal='vehicle'),\n",
      "         Value(\n",
      "             sVal='Empoy Marquez'),\n",
      "         Value(\n",
      "             sVal=\"concept of  falling in love even if you don't see the person\"),\n",
      "         Value(\n",
      "             sVal='Overseas Filipino Workers'),\n",
      "         Value(\n",
      "             sVal='Spring Films'),\n",
      "         Value(\n",
      "             sVal='Pascual'),\n",
      "         Value(\n",
      "             sVal='voice role'),\n",
      "         Value(\n",
      "             sVal='Boy Y\\\\u00f1iguez'),\n",
      "         Value(\n",
      "             sVal='cinematographer'),\n",
      "         Value(\n",
      "             sVal='filmed in Hokkaido'),\n",
      "         Value(\n",
      "             sVal='filmed in Sapporo'),\n",
      "         Value(\n",
      "             sVal='filmed in Otaru'),\n",
      "         Value(\n",
      "             sVal='Osaka Asian Film Festival'),\n",
      "         Value(\n",
      "             sVal='Grand Prix'),\n",
      "         Value(\n",
      "             sVal='Most Promising Talent awards'),\n",
      "         Value(\n",
      "             sVal='film festival'),\n",
      "         Value(\n",
      "             sVal='Metro Manila Film Festival'),\n",
      "         Value(\n",
      "             sVal='Philippines'),\n",
      "         Value(\n",
      "             sVal='Unauthorized release'),\n",
      "         Value(\n",
      "             sVal='Facebook'),\n",
      "         Value(\n",
      "             sVal='first week of August 2017'),\n",
      "         Value(\n",
      "             sVal='by the first week of August 2017'),\n",
      "         Value(\n",
      "             sVal='Leon County'),\n",
      "         Value(\n",
      "             sVal='county'),\n",
      "         Value(\n",
      "             sVal='Panhandle'),\n",
      "         Value(\n",
      "             sVal='Florida'),\n",
      "         Value(\n",
      "             sVal='Juan Ponce de Leon'),\n",
      "         Value(\n",
      "             sVal='rolling hills'),\n",
      "         Value(\n",
      "             sVal=\"north Florida's Red Hills Region\"),\n",
      "         Value(\n",
      "             sVal='basalts of the Triassic and Jurassic'),\n",
      "         Value(\n",
      "             sVal='glacial and interglacial period'),\n",
      "         Value(\n",
      "             sVal='Interglacials'),\n",
      "         Value(\n",
      "             sVal='topography of Leon'),\n",
      "         Value(\n",
      "             sVal='Pleistocene'),\n",
      "         Value(\n",
      "             sVal='Leon County Pleistocene coastal terraces'),\n",
      "         Value(\n",
      "             sVal='Miocene epoch'),\n",
      "         Value(\n",
      "             sVal='Three sites within Leon County'),\n",
      "         Value(\n",
      "             sVal='185 per square mile'),\n",
      "         Value(\n",
      "             sVal='state of Florida'),\n",
      "         Value(\n",
      "             sVal='of open space'),\n",
      "         Value(\n",
      "             sVal='forest and woodlands'),\n",
      "         Value(\n",
      "             sVal='Democratic Party'),\n",
      "         Value(\n",
      "             sVal='all counties in Florida'),\n",
      "         Value(\n",
      "             sVal='85%'),\n",
      "         Value(\n",
      "             sVal='Florida State University'),\n",
      "         Value(\n",
      "             sVal='American public space-grant and sea-grant research university'),\n",
      "         Value(\n",
      "             sVal='Florida State'),\n",
      "         Value(\n",
      "             sVal='United States'),\n",
      "         Value(\n",
      "             sVal='State University System of Florida'),\n",
      "         Value(\n",
      "             sVal='Tallahassee Community College'),\n",
      "         Value(\n",
      "             sVal='Florida College System'),\n",
      "         Value(\n",
      "             sVal='Florida Department of Education'),\n",
      "         Value(\n",
      "             sVal='Southern Association of Colleges and Schools'),\n",
      "         Value(\n",
      "             sVal=\"Bachelor's of Science\"),\n",
      "         Value(\n",
      "             sVal='Associate of Arts'),\n",
      "         Value(\n",
      "             sVal='Associate of Science'),\n",
      "         Value(\n",
      "             sVal='Leon County Public Library'),\n",
      "         Value(\n",
      "             sVal='1993'),\n",
      "         Value(\n",
      "             sVal='Carnegie Library of Tallahassee'),\n",
      "         Value(\n",
      "             sVal='black community'),\n",
      "         Value(\n",
      "             sVal='Florida A&M University'),\n",
      "         Value(\n",
      "             sVal='Jefferson County'),\n",
      "         Value(\n",
      "             sVal='Leon County Public Library System'),\n",
      "         Value(\n",
      "             sVal='Wakulla County'),\n",
      "         Value(\n",
      "             sVal='Tallahassee Commercial Airport'),\n",
      "         Value(\n",
      "             sVal='airport'),\n",
      "         Value(\n",
      "             sVal='Tallahassee International Airport'),\n",
      "         Value(\n",
      "             sVal='Interstate 10'),\n",
      "         Value(\n",
      "             sVal='highway'),\n",
      "         Value(\n",
      "             sVal='U.S. Highway 27'),\n",
      "         Value(\n",
      "             sVal='Highway 27'),\n",
      "         Value(\n",
      "             sVal='U.S. Highway'),\n",
      "         Value(\n",
      "             sVal='U.S. Highway 90'),\n",
      "         Value(\n",
      "             sVal='U.S. Highway 319'),\n",
      "         Value(\n",
      "             sVal='State Road'),\n",
      "         Value(\n",
      "             sVal='State Road 20'),\n",
      "         Value(\n",
      "             sVal='State Road 61'),\n",
      "         Value(\n",
      "             sVal='State Road 155'),\n",
      "         Value(\n",
      "             sVal='State Road 263'),\n",
      "         Value(\n",
      "             sVal='State Road 267'),\n",
      "         Value(\n",
      "             sVal='State Road 363'),\n",
      "         Value(\n",
      "             sVal='Communities'),\n",
      "         Value(\n",
      "             sVal='Cricket Club of India'),\n",
      "         Value(\n",
      "             sVal='Dinsha Wacha Road'),\n",
      "         Value(\n",
      "             sVal='near Churchgate'),\n",
      "         Value(\n",
      "             sVal='in Mumbai'),\n",
      "         Value(\n",
      "             sVal=\"India's counterpart to the Marylebone Cricket Club\"),\n",
      "         Value(\n",
      "             sVal='one of the most prestigious clubs in the nation'),\n",
      "         Value(\n",
      "             sVal='CCI'),\n",
      "         Value(\n",
      "             sVal='BCCI'),\n",
      "         Value(\n",
      "             sVal='state'),\n",
      "         Value(\n",
      "             sVal='stadium'),\n",
      "         Value(\n",
      "             sVal='one of the best cricket pitches and grounds in the region'),\n",
      "         Value(\n",
      "             sVal='5 matches of the ICC Champions Trophy'),\n",
      "         Value(\n",
      "             sVal='Legacy'),\n",
      "         Value(\n",
      "             sVal='Gerald Wilson Orchestra'),\n",
      "         Value(\n",
      "             sVal='2011'),\n",
      "         Value(\n",
      "             sVal='Mack Avenue label'),\n",
      "         Value(\n",
      "             sVal='Gerald Wilson'),\n",
      "         Value(\n",
      "             sVal='Variation on a Theme by Igor Stravinsky'),\n",
      "         Value(\n",
      "             sVal='Virgo'),\n",
      "         Value(\n",
      "             sVal='Variations on Clair de Lune'),\n",
      "         Value(\n",
      "             sVal='Variation on a Theme by Giacomo Puccini'),\n",
      "         Value(\n",
      "             sVal='September Sky'),\n",
      "         Value(\n",
      "             sVal='Darkroom manipulation'),\n",
      "         Value(\n",
      "             sVal='traditional method'),\n",
      "         Value(\n",
      "             sVal='physical rather than virtual techniques'),\n",
      "         Value(\n",
      "             sVal='remove unwanted areas'),\n",
      "         Value(\n",
      "             sVal='change image background'),\n",
      "         Value(\n",
      "             sVal='Jerry Uelsmann'),\n",
      "         Value(\n",
      "             sVal='surrealist imagery'),\n",
      "         Value(\n",
      "             sVal='using digital tools in the darkroom'),\n",
      "         Value(\n",
      "             sVal='in high school'),\n",
      "         Value(\n",
      "             sVal='Dodging and burning'),\n",
      "         Value(\n",
      "             sVal='lighten or darken a part of the photograph'),\n",
      "         Value(\n",
      "             sVal='Cropping'),\n",
      "         Value(\n",
      "             sVal='decide what is left out in the final print'),\n",
      "         Value(\n",
      "             sVal='Wanker'),\n",
      "         Value(\n",
      "             sVal='pejorative term'),\n",
      "         Value(\n",
      "             sVal='Wanker (surname)'),\n",
      "         Value(\n",
      "             sVal='Cockney Wanker'),\n",
      "         Value(\n",
      "             sVal='Wanker Records'),\n",
      "         Value(\n",
      "             sVal='Wanker County'),\n",
      "         Value(\n",
      "             sVal='2005-2006 Session'),\n",
      "         Value(\n",
      "             sVal='Major legislation'),\n",
      "         Value(\n",
      "             sVal='SB 1613'),\n",
      "         Value(\n",
      "             sVal='Law banning the use of cell phones in cars'),\n",
      "         Value(\n",
      "             sVal='John Campbell'),\n",
      "         Value(\n",
      "             sVal='State Senate seat'),\n",
      "         Value(\n",
      "             sVal='Fabian Nez'),\n",
      "         Value(\n",
      "             sVal='Speaker'),\n",
      "         Value(\n",
      "             sVal='Sanhe'),\n",
      "         Value(\n",
      "             sVal='Renhuai City'),\n",
      "         Value(\n",
      "             sVal='north-northwest of downtown Renhuai'),\n",
      "         Value(\n",
      "             sVal='east of the border with Sichuan'),\n",
      "         Value(\n",
      "             sVal='RAF Towyn'),\n",
      "         Value(\n",
      "             sVal='airfield'),\n",
      "         Value(\n",
      "             sVal='west of Machynlleth'),\n",
      "         Value(\n",
      "             sVal='north of Aberystwyth'),\n",
      "         Value(\n",
      "             sVal='8 September 1940'),\n",
      "         Value(\n",
      "             sVal='1945'),\n",
      "         Value(\n",
      "             sVal='Marly'),\n",
      "         Value(\n",
      "             sVal='knight'),\n",
      "         Value(\n",
      "             sVal='Cistercian monastery')]))}Error: TSocket read 0 bytes\n",
      "INFO:llama_index.graph_stores.nebulagraph:Session pool recreated. Query: WITH map{`true`: '-[', `false`: '<-['} AS arrow_l,     map{`true`: ']->', `false`: ']-'} AS arrow_r,     map{`relationship`: \"relationship\"} AS edge_type_map MATCH p=(start)-[e:`relationship`*..1]-()   WHERE id(start) IN $subjs WITH start, id(start) AS vid, nodes(p) AS nodes, e AS rels,  length(p) AS rel_count, arrow_l, arrow_r, edge_type_map WITH   REDUCE(s = vid + '{', key IN [key_ in ['', 'name']     WHERE properties(start)[key_] IS NOT NULL]  | s + key + ': ' +       COALESCE(TOSTRING(properties(start)[key]), 'null') + ', ')      + '}'    AS subj,  [item in [i IN RANGE(0, rel_count - 1)|[nodes[i], nodes[i + 1],      rels[i], typeid(rels[i]) > 0, type(rels[i]) ]] | [    arrow_l[tostring(item[3])] +      item[4] + ':' +      REDUCE(s = '{', key IN SPLIT(edge_type_map[item[4]], ',') |         s + key + ': ' + COALESCE(TOSTRING(properties(item[2])[key]),        'null') + ', ') + '}'      +    arrow_r[tostring(item[3])],    REDUCE(s = id(item[1]) + '{', key IN [key_ in         ['', 'name'] WHERE properties(item[1])[key_]         IS NOT NULL]  | s + key + ': ' +         COALESCE(TOSTRING(properties(item[1])[key]), 'null') + ', ')        + '}'    ]  ] AS rels WITH   REPLACE(subj, ', }', '}') AS subj,  REDUCE(acc = collect(NULL), l in rels | acc + l) AS flattened_rels RETURN   subj,  REPLACE(REDUCE(acc = subj, l in flattened_rels | acc + ' ' + l),     ', }', '}')     AS flattened_rels  LIMIT 100, Param: {'subjs': Value(\n",
      "    lVal=NList(\n",
      "         values=[Value(\n",
      "             sVal='Neal Dunn'),\n",
      "         Value(\n",
      "             sVal='R'),\n",
      "         Value(\n",
      "             sVal='Otaru Music Box Museum'),\n",
      "         Value(\n",
      "             sVal='Otaru'),\n",
      "         Value(\n",
      "             sVal='Northwood Mall'),\n",
      "         Value(\n",
      "             sVal='Tallahassee'),\n",
      "         Value(\n",
      "             sVal='Theobald of Marly'),\n",
      "         Value(\n",
      "             sVal='abbot'),\n",
      "         Value(\n",
      "             sVal='LeRoy Collins'),\n",
      "         Value(\n",
      "             sVal='Governor of Florida'),\n",
      "         Value(\n",
      "             sVal='Economic Offences Wing'),\n",
      "         Value(\n",
      "             sVal='Mumbai police'),\n",
      "         Value(\n",
      "             sVal='Tonyo'),\n",
      "         Value(\n",
      "             sVal='Sapporo'),\n",
      "         Value(\n",
      "             sVal='Kita Kita'),\n",
      "         Value(\n",
      "             sVal='Philippine romantic comedy film'),\n",
      "         Value(\n",
      "             sVal='Sigrid Andrea P. Bernardo'),\n",
      "         Value(\n",
      "             sVal='Alessandra de Rossi and Empoy Marquez'),\n",
      "         Value(\n",
      "             sVal='Lea'),\n",
      "         Value(\n",
      "             sVal='collapses'),\n",
      "         Value(\n",
      "             sVal='vehicle'),\n",
      "         Value(\n",
      "             sVal='Empoy Marquez'),\n",
      "         Value(\n",
      "             sVal=\"concept of  falling in love even if you don't see the person\"),\n",
      "         Value(\n",
      "             sVal='Overseas Filipino Workers'),\n",
      "         Value(\n",
      "             sVal='Spring Films'),\n",
      "         Value(\n",
      "             sVal='Pascual'),\n",
      "         Value(\n",
      "             sVal='voice role'),\n",
      "         Value(\n",
      "             sVal='Boy Y\\\\u00f1iguez'),\n",
      "         Value(\n",
      "             sVal='cinematographer'),\n",
      "         Value(\n",
      "             sVal='filmed in Hokkaido'),\n",
      "         Value(\n",
      "             sVal='filmed in Sapporo'),\n",
      "         Value(\n",
      "             sVal='filmed in Otaru'),\n",
      "         Value(\n",
      "             sVal='Osaka Asian Film Festival'),\n",
      "         Value(\n",
      "             sVal='Grand Prix'),\n",
      "         Value(\n",
      "             sVal='Most Promising Talent awards'),\n",
      "         Value(\n",
      "             sVal='film festival'),\n",
      "         Value(\n",
      "             sVal='Metro Manila Film Festival'),\n",
      "         Value(\n",
      "             sVal='Philippines'),\n",
      "         Value(\n",
      "             sVal='Unauthorized release'),\n",
      "         Value(\n",
      "             sVal='Facebook'),\n",
      "         Value(\n",
      "             sVal='first week of August 2017'),\n",
      "         Value(\n",
      "             sVal='by the first week of August 2017'),\n",
      "         Value(\n",
      "             sVal='Leon County'),\n",
      "         Value(\n",
      "             sVal='county'),\n",
      "         Value(\n",
      "             sVal='Panhandle'),\n",
      "         Value(\n",
      "             sVal='Florida'),\n",
      "         Value(\n",
      "             sVal='Juan Ponce de Leon'),\n",
      "         Value(\n",
      "             sVal='rolling hills'),\n",
      "         Value(\n",
      "             sVal=\"north Florida's Red Hills Region\"),\n",
      "         Value(\n",
      "             sVal='basalts of the Triassic and Jurassic'),\n",
      "         Value(\n",
      "             sVal='glacial and interglacial period'),\n",
      "         Value(\n",
      "             sVal='Interglacials'),\n",
      "         Value(\n",
      "             sVal='topography of Leon'),\n",
      "         Value(\n",
      "             sVal='Pleistocene'),\n",
      "         Value(\n",
      "             sVal='Leon County Pleistocene coastal terraces'),\n",
      "         Value(\n",
      "             sVal='Miocene epoch'),\n",
      "         Value(\n",
      "             sVal='Three sites within Leon County'),\n",
      "         Value(\n",
      "             sVal='185 per square mile'),\n",
      "         Value(\n",
      "             sVal='state of Florida'),\n",
      "         Value(\n",
      "             sVal='of open space'),\n",
      "         Value(\n",
      "             sVal='forest and woodlands'),\n",
      "         Value(\n",
      "             sVal='Democratic Party'),\n",
      "         Value(\n",
      "             sVal='all counties in Florida'),\n",
      "         Value(\n",
      "             sVal='85%'),\n",
      "         Value(\n",
      "             sVal='Florida State University'),\n",
      "         Value(\n",
      "             sVal='American public space-grant and sea-grant research university'),\n",
      "         Value(\n",
      "             sVal='Florida State'),\n",
      "         Value(\n",
      "             sVal='United States'),\n",
      "         Value(\n",
      "             sVal='State University System of Florida'),\n",
      "         Value(\n",
      "             sVal='Tallahassee Community College'),\n",
      "         Value(\n",
      "             sVal='Florida College System'),\n",
      "         Value(\n",
      "             sVal='Florida Department of Education'),\n",
      "         Value(\n",
      "             sVal='Southern Association of Colleges and Schools'),\n",
      "         Value(\n",
      "             sVal=\"Bachelor's of Science\"),\n",
      "         Value(\n",
      "             sVal='Associate of Arts'),\n",
      "         Value(\n",
      "             sVal='Associate of Science'),\n",
      "         Value(\n",
      "             sVal='Leon County Public Library'),\n",
      "         Value(\n",
      "             sVal='1993'),\n",
      "         Value(\n",
      "             sVal='Carnegie Library of Tallahassee'),\n",
      "         Value(\n",
      "             sVal='black community'),\n",
      "         Value(\n",
      "             sVal='Florida A&M University'),\n",
      "         Value(\n",
      "             sVal='Jefferson County'),\n",
      "         Value(\n",
      "             sVal='Leon County Public Library System'),\n",
      "         Value(\n",
      "             sVal='Wakulla County'),\n",
      "         Value(\n",
      "             sVal='Tallahassee Commercial Airport'),\n",
      "         Value(\n",
      "             sVal='airport'),\n",
      "         Value(\n",
      "             sVal='Tallahassee International Airport'),\n",
      "         Value(\n",
      "             sVal='Interstate 10'),\n",
      "         Value(\n",
      "             sVal='highway'),\n",
      "         Value(\n",
      "             sVal='U.S. Highway 27'),\n",
      "         Value(\n",
      "             sVal='Highway 27'),\n",
      "         Value(\n",
      "             sVal='U.S. Highway'),\n",
      "         Value(\n",
      "             sVal='U.S. Highway 90'),\n",
      "         Value(\n",
      "             sVal='U.S. Highway 319'),\n",
      "         Value(\n",
      "             sVal='State Road'),\n",
      "         Value(\n",
      "             sVal='State Road 20'),\n",
      "         Value(\n",
      "             sVal='State Road 61'),\n",
      "         Value(\n",
      "             sVal='State Road 155'),\n",
      "         Value(\n",
      "             sVal='State Road 263'),\n",
      "         Value(\n",
      "             sVal='State Road 267'),\n",
      "         Value(\n",
      "             sVal='State Road 363'),\n",
      "         Value(\n",
      "             sVal='Communities'),\n",
      "         Value(\n",
      "             sVal='Cricket Club of India'),\n",
      "         Value(\n",
      "             sVal='Dinsha Wacha Road'),\n",
      "         Value(\n",
      "             sVal='near Churchgate'),\n",
      "         Value(\n",
      "             sVal='in Mumbai'),\n",
      "         Value(\n",
      "             sVal=\"India's counterpart to the Marylebone Cricket Club\"),\n",
      "         Value(\n",
      "             sVal='one of the most prestigious clubs in the nation'),\n",
      "         Value(\n",
      "             sVal='CCI'),\n",
      "         Value(\n",
      "             sVal='BCCI'),\n",
      "         Value(\n",
      "             sVal='state'),\n",
      "         Value(\n",
      "             sVal='stadium'),\n",
      "         Value(\n",
      "             sVal='one of the best cricket pitches and grounds in the region'),\n",
      "         Value(\n",
      "             sVal='5 matches of the ICC Champions Trophy'),\n",
      "         Value(\n",
      "             sVal='Legacy'),\n",
      "         Value(\n",
      "             sVal='Gerald Wilson Orchestra'),\n",
      "         Value(\n",
      "             sVal='2011'),\n",
      "         Value(\n",
      "             sVal='Mack Avenue label'),\n",
      "         Value(\n",
      "             sVal='Gerald Wilson'),\n",
      "         Value(\n",
      "             sVal='Variation on a Theme by Igor Stravinsky'),\n",
      "         Value(\n",
      "             sVal='Virgo'),\n",
      "         Value(\n",
      "             sVal='Variations on Clair de Lune'),\n",
      "         Value(\n",
      "             sVal='Variation on a Theme by Giacomo Puccini'),\n",
      "         Value(\n",
      "             sVal='September Sky'),\n",
      "         Value(\n",
      "             sVal='Darkroom manipulation'),\n",
      "         Value(\n",
      "             sVal='traditional method'),\n",
      "         Value(\n",
      "             sVal='physical rather than virtual techniques'),\n",
      "         Value(\n",
      "             sVal='remove unwanted areas'),\n",
      "         Value(\n",
      "             sVal='change image background'),\n",
      "         Value(\n",
      "             sVal='Jerry Uelsmann'),\n",
      "         Value(\n",
      "             sVal='surrealist imagery'),\n",
      "         Value(\n",
      "             sVal='using digital tools in the darkroom'),\n",
      "         Value(\n",
      "             sVal='in high school'),\n",
      "         Value(\n",
      "             sVal='Dodging and burning'),\n",
      "         Value(\n",
      "             sVal='lighten or darken a part of the photograph'),\n",
      "         Value(\n",
      "             sVal='Cropping'),\n",
      "         Value(\n",
      "             sVal='decide what is left out in the final print'),\n",
      "         Value(\n",
      "             sVal='Wanker'),\n",
      "         Value(\n",
      "             sVal='pejorative term'),\n",
      "         Value(\n",
      "             sVal='Wanker (surname)'),\n",
      "         Value(\n",
      "             sVal='Cockney Wanker'),\n",
      "         Value(\n",
      "             sVal='Wanker Records'),\n",
      "         Value(\n",
      "             sVal='Wanker County'),\n",
      "         Value(\n",
      "             sVal='2005-2006 Session'),\n",
      "         Value(\n",
      "             sVal='Major legislation'),\n",
      "         Value(\n",
      "             sVal='SB 1613'),\n",
      "         Value(\n",
      "             sVal='Law banning the use of cell phones in cars'),\n",
      "         Value(\n",
      "             sVal='John Campbell'),\n",
      "         Value(\n",
      "             sVal='State Senate seat'),\n",
      "         Value(\n",
      "             sVal='Fabian Nez'),\n",
      "         Value(\n",
      "             sVal='Speaker'),\n",
      "         Value(\n",
      "             sVal='Sanhe'),\n",
      "         Value(\n",
      "             sVal='Renhuai City'),\n",
      "         Value(\n",
      "             sVal='north-northwest of downtown Renhuai'),\n",
      "         Value(\n",
      "             sVal='east of the border with Sichuan'),\n",
      "         Value(\n",
      "             sVal='RAF Towyn'),\n",
      "         Value(\n",
      "             sVal='airfield'),\n",
      "         Value(\n",
      "             sVal='west of Machynlleth'),\n",
      "         Value(\n",
      "             sVal='north of Aberystwyth'),\n",
      "         Value(\n",
      "             sVal='8 September 1940'),\n",
      "         Value(\n",
      "             sVal='1945'),\n",
      "         Value(\n",
      "             sVal='Marly'),\n",
      "         Value(\n",
      "             sVal='knight'),\n",
      "         Value(\n",
      "             sVal='Cistercian monastery')]))}This was due to error: TSocket read 0 bytes, and now retrying.\n",
      "example.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"example.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3cf303f3d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = kg_index.get_networkx_graph()\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "net.show(\"example.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc817148-c947-4af9-96ef-78a6a8e67ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2f11e-a86d-4327-a71f-d51e6dfbe00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35849972-135d-4058-b457-f0d28951279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48bc42-9637-4b35-9311-ea561a964d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
